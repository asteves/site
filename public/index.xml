<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex Stephenson</title>
    <link>/</link>
    <description>Recent content on Alex Stephenson</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2019 00:00:00 +0100</lastBuildDate>
    
	    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Simple Linear Regression</title>
      <link>/courses/econometrics/chap2/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0100</pubDate>
      
      <guid>/courses/econometrics/chap2/</guid>
      <description>

&lt;p&gt;We are interested in studying models that take the following form&lt;/p&gt;

&lt;p&gt;\[y = \beta_0 + \beta_1x + u\]&lt;/p&gt;

&lt;p&gt;where \(\beta_0\) is the intercept, \(\beta_1\) is the slope parameter and u is the error term. In the next set of notes, we will extend this model to situations where we have more than one covariate.&lt;/p&gt;

&lt;p&gt;We can think of \(\beta_0 + \beta_1x\) as the systematic part of y whereas u is the unsystematic part of y. That is, u represents y not explained by x.&lt;/p&gt;

&lt;h2 id=&#34;error-term-assumptions&#34;&gt;Error Term Assumptions&lt;/h2&gt;

&lt;p&gt;In order to make progress, we make the following assumptions about the error term.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;\(E[u] = 0\) as long as an intercept term is included in the equation. Note that this essentially defines the intercept.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;\(E[u|x] = E[u] = 0\). This is the Zero Conditional Mean Assumption for the error term.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The average value of the unobservables is the same across all slices of the population determined by the value of x and is equal to the average of u over the entire population&lt;/li&gt;
&lt;li&gt;By EA.1 that means the average is 0&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;deriving-ols-estimates&#34;&gt;Deriving OLS Estimates&lt;/h2&gt;

&lt;p&gt;To estimate the Population Regression Function (PRF), we need a sample.&lt;/p&gt;

&lt;p&gt;Let \((x_i, y_i): i = 1,&amp;hellip;,n\) be a random sample of size n from the population. We can estimate the PRF by a model:&lt;/p&gt;

&lt;p&gt;\[y = \beta_0 + \beta_1x_i + u_i\] (E.2)&lt;/p&gt;

&lt;p&gt;Error Assumption 2 implies that in the popuation x and u are uncorrelated, and the zero conditional mean assumption for the error implies that \(E[u] = 0\). This implies that the covariance between x and u is 0 or formally:
\[Cov(x,u) = E(xu) = 0\]&lt;/p&gt;

&lt;p&gt;We can rewrite previous equations as follows&lt;/p&gt;

&lt;p&gt;\[E[u] = E[ y - \beta_0 + \beta_1x]\] (E.3)&lt;/p&gt;

&lt;p&gt;\[Cov(x,u) = E[x(y - \beta_0 + \beta_1x)]\] (E.4)&lt;/p&gt;

&lt;p&gt;Our goal is to choose sample \(\hat{\beta_0}\),\(\hat{\beta_1}\) to solve the sample equations:&lt;/p&gt;

&lt;p&gt;\[\frac{1}{n}\sum_{i=1}^n y - \hat{\beta_0} + \hat{\beta_1}x = 0\] (E.5)&lt;/p&gt;

&lt;p&gt;\[\frac{1}{n}\sum_{i=1}^n x_i(y - \hat{\beta_0} + \hat{\beta_1}x) = 0\] (E.6)&lt;/p&gt;

&lt;p&gt;Rewrite E.4&lt;/p&gt;

&lt;p&gt;\[\bar{y} = \hat{\beta_0} + \hat{\beta_1}\bar{x}\] which implies&lt;/p&gt;

&lt;p&gt;\[\beta_0 = \bar{y} - \hat{\beta_1}\bar{x}\]&lt;/p&gt;

&lt;h3 id=&#34;estimating-the-slope-parameter&#34;&gt;Estimating The Slope Parameter&lt;/h3&gt;

&lt;p&gt;Drop the \(\frac{1}{n}\) in E.5 because it does not affect the solution. Plug in \(\bar{y} - \hat{\beta_1}\bar{x}\) for \(\beta_0\) which yields the equation&lt;/p&gt;

&lt;p&gt;\[\sum_{i=1}^n x_i(\bar{y} - \hat{\beta_1}\bar{x}) - \hat{\beta_1}x) = 0\]&lt;/p&gt;

&lt;p&gt;Rearrange terms to get the y&amp;rsquo;s and the x&amp;rsquo;s on opposite sides of the equation.
\[\sum_{i=1}^n x_i(y_i - \bar{y})\]
\[\hat{\beta_1}\sum x_i(x_i - \bar{x})\]&lt;/p&gt;

&lt;p&gt;Setting these equal to each other and using properties of the sum operator, we can rewrite the the top sum to be \(Cov(x,y)\) and the bottom sum to \(V(x)\). As long as \(V(x) &amp;gt; 0\),&lt;/p&gt;

&lt;p&gt;\[\hat{\beta_1} = \frac{\hat{Cov(x,y)}}{\hat{V(x)}}\]&lt;/p&gt;

&lt;p&gt;In words, the slope parameter estimate is the sample covariance of x and y divided by the sample variance of x. We refer to this as the OLS procedure and the OLS regression line as&lt;/p&gt;

&lt;p&gt;\[\hat{y} = \hat{\beta_0} + \hat{\beta_1}x\]&lt;/p&gt;

&lt;h2 id=&#34;algebraic-properties-of-ols-on-any-sample-of-data&#34;&gt;Algebraic Properties of OLS on Any Sample of Data&lt;/h2&gt;

&lt;p&gt;The following hold by construction for any sample of data estimated by OLS&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The sum and therefore sample average of the residuals is 0. This is because the OLS estimates are chosen to make the residuals sum to 0.&lt;/li&gt;
&lt;li&gt;Sample covariance between regressors and OLS residuals is 0&lt;/li&gt;
&lt;li&gt;The point \((\bar{x}, \bar{y})\) is always on the OLS regression line&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;variation-in-y&#34;&gt;Variation in Y&lt;/h2&gt;

&lt;p&gt;We can view OLS as decomposing each \(y_i\) into two parts, a fitted value and a residual. There are three parts of this decomposition: the total sum of squares (SST), the explained sum of squares (SSE), and the residual sum of squares (SSR).&lt;/p&gt;

&lt;p&gt;\[SST = \sum_{i=1}^n (y_i -\bar{y})^2\]&lt;/p&gt;

&lt;p&gt;\[SSE = \sum_{i=1}^n (\hat{y_i} -\bar{y})^2\]&lt;/p&gt;

&lt;p&gt;\[SSR = \sum_{i=1}^n \hat{u}^2\]&lt;/p&gt;

&lt;p&gt;SST is a measure of total sample variation in the \(y_i\)&amp;rsquo;s. Dividing SST by n-1 gets us the sample variance of y.&lt;/p&gt;

&lt;p&gt;The Total Variation in y is SST = SSE + SSR.&lt;/p&gt;

&lt;p&gt;To derive&lt;/p&gt;

&lt;p&gt;\[\sum_{i=1}^n (y_i -\bar{y})^2\]&lt;/p&gt;

&lt;p&gt;\[\sum_{i=1}^n [(y_i - \hat{y_i}) + (\hat{y_i}-\bar{y})]^2\]&lt;/p&gt;

&lt;p&gt;\[\sum_{i=1}^n [\hat{u_i} + (\hat{y_i}-\bar{y})]^2\]&lt;/p&gt;

&lt;p&gt;Expand out the sum and replace with definitions to get&lt;/p&gt;

&lt;p&gt;\[SSR + 2Cov(\hat{u}, \hat{y}) + SSE\]&lt;/p&gt;

&lt;p&gt;Since the covariance between u and y is 0, that term drops out.&lt;/p&gt;

&lt;h2 id=&#34;goodness-of-fit&#34;&gt;Goodness of Fit&lt;/h2&gt;

&lt;p&gt;The ratio of the explained sample variation in y by x is known as \(R^2\) and defined:&lt;/p&gt;

&lt;p&gt;\[R^2 = 1 - \frac{SSR}{SST}\]&lt;/p&gt;

&lt;h2 id=&#34;expected-values-and-unbiasedness-of-ols-estimators&#34;&gt;Expected Values and Unbiasedness of OLS Estimators&lt;/h2&gt;

&lt;p&gt;OLS is an unbiased estimator of the population model provided the following assumptions hold. These assumptions are also known as Gauss-Markov assumptions.&lt;/p&gt;

&lt;h3 id=&#34;a1-linear-in-paramters&#34;&gt;A1. Linear in paramters&lt;/h3&gt;

&lt;p&gt;In the population model, y is related to x and u&lt;/p&gt;

&lt;p&gt;\[y = \beta_0 + \beta_1x + u \]&lt;/p&gt;

&lt;h3 id=&#34;a2-random-sample&#34;&gt;A2. Random Sample&lt;/h3&gt;

&lt;p&gt;We have a random sample of size n from the population model&lt;/p&gt;

&lt;h3 id=&#34;a3-sample-variation-in-x&#34;&gt;A3. Sample variation in x&lt;/h3&gt;

&lt;p&gt;The sample outcomes \(x_i: i = 1,2,&amp;hellip;, n\) are not all the same value. If they are, there is no variance of X and so \(\beta_1\) cannot be estimated.&lt;/p&gt;

&lt;h3 id=&#34;a4-zero-conditional-mean-of-the-error&#34;&gt;A4. Zero Conditional Mean of the Error&lt;/h3&gt;

&lt;p&gt;For a random sample, this assumption implies&lt;/p&gt;

&lt;p&gt;\[E(u_i|x_i) = 0: \forall i \in [0,1,&amp;hellip;n]\]&lt;/p&gt;

&lt;p&gt;A4 is violated whenever we think that u and x are correlated. In the simple bivariate case, an example might be using the variable education to predict salary. education is correlated with many variables, including income and family history. These may affect salary and therefore will give us biased results.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: We can write the slope estimator \(\beta_1\) in a slightly different way&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;\[\hat{\beta_1} = \frac{\sum_{i=1}^n (x_i - \bar{x})*(\beta_0 - \beta_1x + u_i)}{SST_x}\]&lt;/p&gt;

&lt;p&gt;\[\hat{\beta_1} = \beta_0 \sum_{i=1}^n\ + \beta_1\sum_{i=1}^n x_i(x_i -\bar{x}) + \sum_{i=1}^n u_i(x_i - \bar{x})\]&lt;/p&gt;

&lt;p&gt;The first term sums to 0 and drops out. Thus:&lt;/p&gt;

&lt;p&gt;\[\hat{\beta_1} = \beta_1 + \frac{\sum_{i=1}^n u_i(x_i - \bar{x})}{SST_x}\]&lt;/p&gt;

&lt;p&gt;We now have all the information we need to prove that OLS is unbiased. Unbiasedness is a feature of the sampling distributions of \(\hat{\beta_0}\) and \(\hat{\beta_1}\). Unbiasedness says nothing about the estimates for any &lt;em&gt;given sample&lt;/em&gt; we may draw.&lt;/p&gt;

&lt;h3 id=&#34;theorem-1-using-a1-a4-ols-produces-unbiased-estimates&#34;&gt;Theorem 1: Using A1-A4 OLS produces unbiased estimates&lt;/h3&gt;

&lt;p&gt;\(E(\hat{\beta_0}) = \beta_0\) and \(E(\hat{\beta_1}) = \beta_1\)for any values of \(\beta_0\) and \(\beta_1\).&lt;/p&gt;

&lt;p&gt;Proof:&lt;/p&gt;

&lt;p&gt;In this proof the expected values are conditional on sample values of the independent variable x. Because \(SST_x\) and \((x_i - \bar(x))\) are functions on of \(x_i\) they are non-random once we condition on x.&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_1}] = E[\beta_1 + \frac{\sum_{i=1}^n u_i(x_i - \bar{x})}{SST_x}]\]&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_1}] = \beta_1 + \frac{\sum_{i=1}^n E[u_i(x_i - \bar{x})]}{SST_x}\]&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_1}] = \beta_1 + \frac{\sum_{i=1}^n 0 (x_i - \bar{x})}{SST_x}\]&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_1}] = \beta_1\]&lt;/p&gt;

&lt;p&gt;We can also prove the same for \(\beta_0\).&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_0}] = \beta_0 + E[(\beta_1 - \hat{\beta_1}\bar{x} + E[\bar{u}]\]&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_0}] = \beta_0 + E[(\beta_1 - \hat{\beta_1}\bar{x} + 0\]&lt;/p&gt;

&lt;p&gt;\[E[\hat{\beta_0}] = \beta_0\]&lt;/p&gt;

&lt;p&gt;In the last equation, because \(\hat{\beta_1} = \beta_1\) the second term drops out.&lt;/p&gt;

&lt;h2 id=&#34;variances-of-ols-estimators&#34;&gt;Variances of OLS Estimators&lt;/h2&gt;

&lt;p&gt;An additional assumption we can make about the variance of the OLS estimators is that the error u has the same variances conditional on any value of the explanatory variable.&lt;/p&gt;

&lt;p&gt;\[V(u|x) = \sigma^2\]&lt;/p&gt;

&lt;p&gt;By adding this assumption, which to be clear will break down horribly if it is violated, we can prove the following theorem.&lt;/p&gt;

&lt;h3 id=&#34;theorem-2-using-assumptions-1-4-and-homoskedastic-error-assumption&#34;&gt;Theorem 2: Using assumptions 1-4 and homoskedastic error assumption&lt;/h3&gt;

&lt;p&gt;\[V(\hat{\beta_1}) = \frac{\sigma^2}{SST_x}\] and \[V(\hat{\beta_0}) = \frac{\sigma^2\frac{1}{n}\sum_{i=1}^n x_i^2}{\sum_{i=1}^n(x_i - \bar{x})^2}\]&lt;/p&gt;

&lt;p&gt;where these are conditioned on the sample values.&lt;/p&gt;

&lt;p&gt;Proof for \(V(\hat{\beta_1})\)&lt;/p&gt;

&lt;p&gt;\[V(\hat{\beta_1}) = \frac{1^2}{SST_x^2}V(\sum_{i=1}^n u_i(x_i - \bar{x}))\]&lt;/p&gt;

&lt;p&gt;Substitute \(d_i = (x_i - \bar{x})\)&lt;/p&gt;

&lt;p&gt;\[V(\hat{\beta_1}) = \frac{1^2}{SST_x^2}\sum_{i=1}^n u_i d_i^2\]&lt;/p&gt;

&lt;p&gt;Since \(V(u_i) = \sigma^2 : \forall i\) we can substitute that constant into the equation.&lt;/p&gt;

&lt;p&gt;\[V(\hat{\beta_1}) = \frac{1}{SST_x^2}\sigma^2 \sum_{i=1}^n d_i^2\]&lt;/p&gt;

&lt;p&gt;Observe that the second RHS term is just \(SST_x\) after pulling out the constant, we can rewrite as&lt;/p&gt;

&lt;p&gt;\[V(\hat{\beta_1}) = \frac{\sigma^2 SST_x}{SST_x^2}\]&lt;/p&gt;

&lt;p&gt;which reduces to our stated result.&lt;/p&gt;

&lt;p&gt;Now that we know the way to estimate the variance, we can ask the following question. How does \(V(\hat{\beta_1})\) depend on error variance?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The larger the error variance, the larger \(V(\hat{\beta_1})\).&lt;/li&gt;
&lt;li&gt;The larger the \(V(x)\), the smaller \(V(\hat{\beta_1})\)&lt;/li&gt;
&lt;li&gt;As sample size increases, the total variation in x increases which leads to a decrease in \(V(\hat{\beta_1})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;estimating-the-erroro-variance&#34;&gt;Estimating the Erroro Variance&lt;/h2&gt;

&lt;p&gt;Errors are never observed. Instead, we observe residuals that we can compute from our sample data. We can write the errors as a function of the residuals.&lt;/p&gt;

&lt;p&gt;\[\hat{u_i} = u_i - (\hat{\beta_0} - \beta_0) - (\hat{\beta_1} - \beta_1)x\]&lt;/p&gt;

&lt;p&gt;One problem that we run into is that using the residuals as an estimator is biased without correction because it does not take into account two restrictions for OLS residuals. OLS residuals have to sum to 0 and have a 0 covariance between x and u. Formally,&lt;/p&gt;

&lt;p&gt;\[\sum_{i=1}^n \hat{u_i} = 0\]&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;\[\sum_{i=1}^n \hat{u_i}x_i = 0\].&lt;/p&gt;

&lt;p&gt;Thus we need to correct by n-2 degrees of freedom for an unbiased estimator. When we do so, we get the following.&lt;/p&gt;

&lt;p&gt;\[\hat{\sigma}^2 = \hat{s}^2 = \frac{1}{n-2}\sum_{i=1}^n\hat{u_i}^2\]&lt;/p&gt;

&lt;p&gt;\[\hat{\sigma}^2 = \frac{SSR}{n-2}\]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Notes for Week 1</title>
      <link>/courses/psfive/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      
      <guid>/courses/psfive/example1/</guid>
      <description>

&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;

&lt;p&gt;Forthcoming&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multiple Linear Regression</title>
      <link>/courses/econometrics/chap3/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0100</pubDate>
      
      <guid>/courses/econometrics/chap3/</guid>
      <description>&lt;p&gt;We are now going to extend our previous discussion of Simple Linear Regression into the multiple variate case. Here we consider models that include more than one independent variable.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning R: Dealing Playcards</title>
      <link>/post/learning-r-dealing-playcards/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/learning-r-dealing-playcards/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;There are lots of benefits to learning a computer language, even if only learning enough to make yourself dangerous to your own computer. In this post, I&amp;rsquo;ll provide a purposely dumb way to shuffle playing cards and deal hands to different players. In doing so, I will demonstrate a variety of basic operations in the R language.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# This is a comment. We write comments for future programmers 
# to be able to read and understand our code. 
# The most common future programmer to read your code is you 
# in the future. 
# Be nice to future you. 

# Comments in R start with a #. 
# R will ignore everything after a # on the same line

# These next lines set a random number seed 
# and then sample 10 numbers from 1 to 100 with replacement. 
#As a result, we might get the same number more than once. 

set.seed(106108)
sample(x = 1:100, size = 10,replace = TRUE, prob = NULL)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] 83 18 20  2 69 93 20 93 68 33
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sample() is a function, or a tool to get stuff done. We can tell something is a function because it has () immediately following it. Note that functions are case sensitive. R does not know what Sample() means. sample comes with the base R distribution, which means you don&amp;rsquo;t have to write it yourself. sample takes four arguments. When googling you may also see arguments referred to as parameters. They are the information the function needs to work.&lt;/p&gt;

&lt;p&gt;The four arguments are x, which is a vector of elements. In this case x is every number from 1 to 100. The second argument is size, which is the number of elements we want. In our case, that is 10 numbers. The third argument is replace, which determines whether we want to sample with or without replacement. The final argument is prob, which we ignore by setting it to NULL.&lt;/p&gt;

&lt;h2 id=&#34;dealing-cards&#34;&gt;Dealing Cards&lt;/h2&gt;

&lt;p&gt;Sampling with replacement comes up a lot in applications with simple random sampling, but for dealing cards we want to sample without replacement. When we deal a playing card, we do not deal that playing card again to another player.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s use R to assign playing cards at random for practice. First, we need to create a vector of playing cards. This will be a string vector, which means that each element will be a piece of text instead of just a number. To R, &amp;ldquo;10&amp;rdquo; is different than 10.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# First, create a vector of cards and assign it the variable cards 
cardTypes &amp;lt;- c(2:10, &amp;quot;J&amp;quot;,&amp;quot;Q&amp;quot;,&amp;quot;K&amp;quot;, &amp;quot;A&amp;quot;)

# R now knows about the existence of cardTypes. 
# We will print out the vector to confirm 
print(cardTypes)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;2&amp;quot;  &amp;quot;3&amp;quot;  &amp;quot;4&amp;quot;  &amp;quot;5&amp;quot;  &amp;quot;6&amp;quot;  &amp;quot;7&amp;quot;  &amp;quot;8&amp;quot;  &amp;quot;9&amp;quot;  &amp;quot;10&amp;quot; &amp;quot;J&amp;quot;  &amp;quot;Q&amp;quot;  &amp;quot;K&amp;quot;  &amp;quot;A&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we need to attach the suit to each card. In R, one way to combine text is to use paste(). Note that paste() has parentheses, so it is a function. To look up what arguments we need we type ?paste into the console.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Attach suits to each card 
hearts = paste(cardTypes, &amp;quot;H&amp;quot;, sep = &amp;quot;&amp;quot;)
spades = paste(cardTypes, &amp;quot;S&amp;quot;, sep = &amp;quot;&amp;quot;)
clubs = paste(cardTypes, &amp;quot;C&amp;quot;, sep = &amp;quot;&amp;quot;)
diamonds = paste(cardTypes, &amp;quot;D&amp;quot;, sep = &amp;quot;&amp;quot;)

# combine our playing cards into one vector  
playingCards = c(hearts, spades, clubs, diamonds)
print(playingCards)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;2H&amp;quot;  &amp;quot;3H&amp;quot;  &amp;quot;4H&amp;quot;  &amp;quot;5H&amp;quot;  &amp;quot;6H&amp;quot;  &amp;quot;7H&amp;quot;  &amp;quot;8H&amp;quot;  &amp;quot;9H&amp;quot;  &amp;quot;10H&amp;quot; &amp;quot;JH&amp;quot;  &amp;quot;QH&amp;quot; 
## [12] &amp;quot;KH&amp;quot;  &amp;quot;AH&amp;quot;  &amp;quot;2S&amp;quot;  &amp;quot;3S&amp;quot;  &amp;quot;4S&amp;quot;  &amp;quot;5S&amp;quot;  &amp;quot;6S&amp;quot;  &amp;quot;7S&amp;quot;  &amp;quot;8S&amp;quot;  &amp;quot;9S&amp;quot;  &amp;quot;10S&amp;quot;
## [23] &amp;quot;JS&amp;quot;  &amp;quot;QS&amp;quot;  &amp;quot;KS&amp;quot;  &amp;quot;AS&amp;quot;  &amp;quot;2C&amp;quot;  &amp;quot;3C&amp;quot;  &amp;quot;4C&amp;quot;  &amp;quot;5C&amp;quot;  &amp;quot;6C&amp;quot;  &amp;quot;7C&amp;quot;  &amp;quot;8C&amp;quot; 
## [34] &amp;quot;9C&amp;quot;  &amp;quot;10C&amp;quot; &amp;quot;JC&amp;quot;  &amp;quot;QC&amp;quot;  &amp;quot;KC&amp;quot;  &amp;quot;AC&amp;quot;  &amp;quot;2D&amp;quot;  &amp;quot;3D&amp;quot;  &amp;quot;4D&amp;quot;  &amp;quot;5D&amp;quot;  &amp;quot;6D&amp;quot; 
## [45] &amp;quot;7D&amp;quot;  &amp;quot;8D&amp;quot;  &amp;quot;9D&amp;quot;  &amp;quot;10D&amp;quot; &amp;quot;JD&amp;quot;  &amp;quot;QD&amp;quot;  &amp;quot;KD&amp;quot;  &amp;quot;AD&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Confirm that we have 35 elements
print(length(playingCards))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have our playing cards loaded into R, we can use sample like before to assign them along with a new function called split(). split() requires two arguments, a vector and the groups. We can always see what arguments split() takes with ?split. Note that the help page has more than two arguments, but we only need to provide two because the others have sensible defaults.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# One of the cool things about functions in R is 
# that we can use them inside other functions. 
#Our tools work on other tools. 
#The groups argument is called f. You can see on the help page why. 

# Here we are hardcoding that we have seven players. If you were to 
# rewrite this code in the future, this is one place you might want to 
# revise and write your own function
hands = split(x = sample(playingCards, 35, replace = F), f = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;3&amp;quot;,&amp;quot;4&amp;quot;,&amp;quot;5&amp;quot;,&amp;quot;6&amp;quot;,&amp;quot;7&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our new object groups looks different than our other objects. That is because it is a &amp;ldquo;list&amp;rdquo; instead of a vector. A list is a collection of vectors that can have different types. We will learn about lists more as we move through the semester.&lt;/p&gt;

&lt;p&gt;Here are the hands we dealt&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;print(hands)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $`1`
## [1] &amp;quot;QD&amp;quot; &amp;quot;4C&amp;quot; &amp;quot;3H&amp;quot; &amp;quot;6C&amp;quot; &amp;quot;QS&amp;quot;
## 
## $`2`
## [1] &amp;quot;3D&amp;quot; &amp;quot;QH&amp;quot; &amp;quot;4H&amp;quot; &amp;quot;2S&amp;quot; &amp;quot;8H&amp;quot;
## 
## $`3`
## [1] &amp;quot;7C&amp;quot; &amp;quot;KS&amp;quot; &amp;quot;KH&amp;quot; &amp;quot;2H&amp;quot; &amp;quot;4S&amp;quot;
## 
## $`4`
## [1] &amp;quot;9D&amp;quot; &amp;quot;KC&amp;quot; &amp;quot;9S&amp;quot; &amp;quot;9H&amp;quot; &amp;quot;4D&amp;quot;
## 
## $`5`
## [1] &amp;quot;7H&amp;quot; &amp;quot;JD&amp;quot; &amp;quot;8S&amp;quot; &amp;quot;9C&amp;quot; &amp;quot;3S&amp;quot;
## 
## $`6`
## [1] &amp;quot;8C&amp;quot; &amp;quot;6H&amp;quot; &amp;quot;7D&amp;quot; &amp;quot;AS&amp;quot; &amp;quot;5C&amp;quot;
## 
## $`7`
## [1] &amp;quot;AD&amp;quot;  &amp;quot;7S&amp;quot;  &amp;quot;AC&amp;quot;  &amp;quot;5H&amp;quot;  &amp;quot;10C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is all of our code in one place.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Set a random number seed for reproducibility 
set.seed(106108)

# Create a vector of to represent card types and assign it the variable cards 
cardTypes &amp;lt;- c(2:10, &amp;quot;J&amp;quot;,&amp;quot;Q&amp;quot;,&amp;quot;K&amp;quot;, &amp;quot;A&amp;quot;)

# Attach suits to each card 
hearts = paste(cardTypes, &amp;quot;H&amp;quot;, sep = &amp;quot;&amp;quot;)
spades = paste(cardTypes, &amp;quot;S&amp;quot;, sep = &amp;quot;&amp;quot;)
clubs = paste(cardTypes, &amp;quot;C&amp;quot;, sep = &amp;quot;&amp;quot;)
diamonds = paste(cardTypes, &amp;quot;D&amp;quot;, sep = &amp;quot;&amp;quot;)

# combine our playing cards into one vector along with the two jokers 
playingCards = c(hearts, spades, clubs, diamonds)

# Deal hands
hands = split(x = sample(playingCards, 35, replace = F), f = c(1,2,3,4,5,6,7))
print(hands)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $`1`
## [1] &amp;quot;KC&amp;quot; &amp;quot;JD&amp;quot; &amp;quot;4D&amp;quot; &amp;quot;9D&amp;quot; &amp;quot;9S&amp;quot;
## 
## $`2`
## [1] &amp;quot;7S&amp;quot; &amp;quot;8D&amp;quot; &amp;quot;2D&amp;quot; &amp;quot;KD&amp;quot; &amp;quot;7D&amp;quot;
## 
## $`3`
## [1] &amp;quot;6S&amp;quot; &amp;quot;5H&amp;quot; &amp;quot;6D&amp;quot; &amp;quot;JS&amp;quot; &amp;quot;6C&amp;quot;
## 
## $`4`
## [1] &amp;quot;8S&amp;quot;  &amp;quot;8C&amp;quot;  &amp;quot;QH&amp;quot;  &amp;quot;10D&amp;quot; &amp;quot;5C&amp;quot; 
## 
## $`5`
## [1] &amp;quot;3H&amp;quot; &amp;quot;3D&amp;quot; &amp;quot;KS&amp;quot; &amp;quot;4H&amp;quot; &amp;quot;2S&amp;quot;
## 
## $`6`
## [1] &amp;quot;6H&amp;quot; &amp;quot;7C&amp;quot; &amp;quot;AD&amp;quot; &amp;quot;5S&amp;quot; &amp;quot;2H&amp;quot;
## 
## $`7`
## [1] &amp;quot;4C&amp;quot; &amp;quot;7H&amp;quot; &amp;quot;JC&amp;quot; &amp;quot;KH&amp;quot; &amp;quot;9H&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Randomization Inference: A Simple Example</title>
      <link>/post/randomization-inference-a-simple-example/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/randomization-inference-a-simple-example/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This simulation is an example of randomization inference.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(8675309)
library(dplyr)
library(ggplot2)
library(readr)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To understand how the public perceives Donald Trump&amp;rsquo;s tweets, YouGov &lt;a href=&#34;https://tweetindex.yougov.com&#34; target=&#34;_blank&#34;&gt;runs a poll&lt;/a&gt; that asks a representative sample of the US population to rate each tweet the day they are published. Trump&amp;rsquo;s writing style when tweeting is often hyperbolic, with certain words in all-caps and extending out others (&amp;ldquo;sooooo&amp;rdquo;) for effect.&lt;/p&gt;

&lt;p&gt;To show how randomization inference works, let&amp;rsquo;s simulate some Trump tweets based on the YouGov scoring system. Further, let&amp;rsquo;s suppose for the sake of argument that Trump randomly inserts hyperbolic phrases into his tweets.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Generate some tweets 
tweets &amp;lt;- data.frame(tweet = c(1:20),
                     score_obs = round(rnorm(20, 0, 36)),
                     exclamation = sample(0:1, 20, replace = T))%&amp;gt;%
    mutate(Y_i1 = ifelse(exclamation == 1, score_obs, NA),
           Y_i0 = ifelse(exclamation == 0, score_obs, NA))
glimpse(tweets)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 20
## Variables: 5
## $ tweet       &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…
## $ score_obs   &amp;lt;dbl&amp;gt; -36, 26, -22, 73, 38, 36, 1, 24, 21, 33, -56, 37, 5,…
## $ exclamation &amp;lt;int&amp;gt; 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1…
## $ Y_i1        &amp;lt;dbl&amp;gt; NA, NA, NA, 73, 38, NA, 1, 24, 21, NA, -56, NA, 5, -…
## $ Y_i0        &amp;lt;dbl&amp;gt; -36, 26, -22, NA, NA, 36, NA, NA, NA, 33, NA, 37, NA…
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For this simulation, exclamation is a treatment assignment and we want to know the effect that it has on the score of the tweets.&lt;/p&gt;

&lt;h2 id=&#34;sharp-null-hypothesis&#34;&gt;Sharp Null Hypothesis&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Fill in potential outcomes to make the Sharp Null
tweets_ri = tweets %&amp;gt;%
    mutate(Y_i1 = ifelse(is.na(Y_i1), Y_i0, Y_i1),
           Y_i0 = ifelse(is.na(Y_i0), Y_i1, Y_i0))%&amp;gt;%
    select(Y_i1, Y_i0, exclamation, score_obs)
glimpse(tweets_ri)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Observations: 20
## Variables: 4
## $ Y_i1        &amp;lt;dbl&amp;gt; -36, 26, -22, 73, 38, 36, 1, 24, 21, 33, -56, 37, 5,…
## $ Y_i0        &amp;lt;dbl&amp;gt; -36, 26, -22, 73, 38, 36, 1, 24, 21, 33, -56, 37, 5,…
## $ exclamation &amp;lt;int&amp;gt; 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1…
## $ score_obs   &amp;lt;dbl&amp;gt; -36, 26, -22, 73, 38, 36, 1, 24, 21, 33, -56, 37, 5,…
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First we take a difference in means in our observed values, our average treatment effect (ATE). We are going to compare this value to a distribution created by randomizing treatment assignment under the assumption that the true potential outcomes are identical and so there is no difference in treatment and control. This is the Sharp Null Hypothesis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ATE = mean(tweets_ri$score_obs[tweets_ri$exclamation == 1]) - mean(tweets_ri$score_obs[tweets_ri$exclamation == 0])
ATE
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] -8
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;simulation&#34;&gt;Simulation&lt;/h2&gt;

&lt;p&gt;To apply randomization inference, we first create all possible treatment vectors.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;poss_treatments = matrix(NA, 10000, 20)
for(i in 1:nrow(poss_treatments)){
    poss_treatments[i,] = sample(tweets_ri$exclamation, 20, replace = F)
}

# Keep only unique treamtent assignments 
poss_treatments = unique(poss_treatments)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we calculate the average treatment effect for each possible randomization&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;poss_ate = NA 
for(i in 1:nrow(poss_treatments)){
    mean_w_exclam = mean(tweets_ri$score_obs[poss_treatments[i,]== 1])
    
    mean_wo_exclam = mean(tweets_ri$score_obs[poss_treatments[i, ]== 0])
    
    poss_ate[i] = mean_w_exclam - mean_wo_exclam
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To evaluate whether our observed average treatment effect is significant, we can plot the distribution of our randomization. Code for that is given below.&lt;/p&gt;

&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(as.data.frame(poss_ate), aes(x = poss_ate))+
    geom_histogram(aes(y=..density..), binwidth = 1)+
    geom_vline(xintercept = ATE, color = &amp;quot;red&amp;quot;, size = 1)+
    theme_minimal()+
        xlab(&amp;quot;Randomized Average Treatment Effects&amp;quot;)+
        ylab(&amp;quot;Density&amp;quot;)+
        ggtitle(&amp;quot;Randomization Inference of the Effect of Exclamations\nin Donald Trump&#39;s Tweets&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/post/2019-06-02-randomization-inference-a-simple-example_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now, we can also calculate a p-value.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# One tailed 
sum(poss_ate&amp;gt;=ATE)/length(poss_ate)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 0.6925842
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or a Two tailed p-value.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Two tailed
sum(abs(poss_ate)&amp;gt;=ATE)/length(poss_ate)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Given how we created our data, it is unsurprising that the p-value is not signficant. What is practically helpful is the procedure for simulation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using pdftools to Extract Vote Data</title>
      <link>/post/using-pdftools-to-extract-vote-data/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/using-pdftools-to-extract-vote-data/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Suppose you are a concerned citizen who would like to know how voters in a state voted. Perhaps you are a voter in a state with &lt;a href=&#34;https://www.vice.com/en_us/article/vba4vx/corruption-is-rampant-and-new-jersey-is-cool-with-it&#34; target=&#34;_blank&#34;&gt;rampant corruption&lt;/a&gt; or perhaps you are a voter in a state that does not have &lt;a href=&#34;https://www.app.com/story/news/politics/elections/2018/10/22/new-jersey-voting-machines-security/1656558002/&#34; target=&#34;_blank&#34;&gt;paper backups for voting machines&lt;/a&gt;. Perhaps you are just masochistic enough to be interested in pulling tables out of reasonably well formed pdfs. The following is a code example for the last one.&lt;/p&gt;

&lt;p&gt;Fortunately (or unfortunately) for us, the state of New Jersey still provides their official election results in pdf files instead of a common data format like csv or even an Excel file. Copying each item by hand risks user error through fat fingers, sheer tedium, or great displeasure at a state in the 21st Century still outputting results to pdf. Therefore, it is much preferable to search for a code solution.&lt;/p&gt;

&lt;p&gt;Each county in New Jersey reports Senate results separately. Here&amp;rsquo;s Atlantic County&amp;rsquo;s &lt;a href=&#34;https://preview.tinyurl.com/y3zumyjk&#34; target=&#34;_blank&#34;&gt;precinct results&lt;/a&gt; for the 2018 Senate Race. The table that we are going to extract looks like &lt;a href=&#34;https://imgur.com/KEFhzjv&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s one way to pull out the data, using some knowledge about who ran. I make use of tidyverse functions and pdftools. Each step of the function is commented.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
library(pdftools)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once those are loaded, we can write our function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Remove columns that are all NAs
not_all_na &amp;lt;- function(x){
    !all(is.na(x))
}

senate_clean_table &amp;lt;- function(tbl){
    # Remove commas and split on new lines 
    tables &amp;lt;- NULL
    tbl &amp;lt;- str_replace_all(tbl,pattern = &amp;quot;,&amp;quot;, &amp;quot;&amp;quot;)%&amp;gt;%
        # We can see the table ends with the string NJDOE
        str_replace_all(&amp;quot;Total[:print:]+&amp;quot;, &amp;quot;NJDOE&amp;quot;)%&amp;gt;%
        # Split on new lines 
        str_split(pattern = &amp;quot;\n&amp;quot;, simplify = TRUE)
        
    # Some pdfs may be more than one page, so loop over all pages
    # Atlantic County will only run this loop once
    for(i in 1:dim(tbl)[1]){
    
        # Find the county name and save name to object 
        county_cell &amp;lt;- stringr::str_which(tbl[i,], &amp;quot;County&amp;quot;)
        county_name &amp;lt;- tbl[i,county_cell]%&amp;gt;%
        stringr::str_squish()

        # Find the senate candidates cell 
        # Pull out candidates, turn them into a vector 
        # Keep only the last names 
        candidates_cell &amp;lt;- stringr::str_which(tbl[i,], &amp;quot;Robert&amp;quot;)
        candidates &amp;lt;- tbl[i, candidates_cell] %&amp;gt;% 
            trimws()%&amp;gt;%
            str_squish()%&amp;gt;%
            str_replace_all(pattern = &amp;quot; R. &amp;quot;, &amp;quot; &amp;quot;)%&amp;gt;%
            str_replace_all(pattern = &amp;quot; Lynn &amp;quot;, &amp;quot; &amp;quot;)%&amp;gt;%
            str_split(pattern = &amp;quot;\\s&amp;quot;)
        candidates &amp;lt;- unlist(candidates)
        
        # Because each candidate only has two names, after we remove the 
        # initials R recycles and keeps every other cell, which is last names 
        candidates &amp;lt;- candidates[c(FALSE, TRUE)]
        
        # Find the party cell. The actual table starts after this one
        party_cell &amp;lt;- stringr::str_which(tbl[i,], &amp;quot;Democratic&amp;quot;)
       
        # Start the data frame 
        table_start &amp;lt;- party_cell + 1
        
        # Find the line with totals. The last line of interest is 
        # directly before it 
        table_end &amp;lt;- stringr::str_which(tbl[i,], &amp;quot;NJDOE&amp;quot;)[1] -1
    
        # Subset to the table of interest 
        table &amp;lt;- tbl[i, table_start:table_end]
        
        # Create a delimiter everywhere there are 2 spaces 
        table &amp;lt;- str_replace_all(table, &amp;quot;\\s{2,}&amp;quot;, &amp;quot;|&amp;quot;)
        
        # Now we can pull out the data
        
        # Make a text connection and read that in as a dataframe
        text_con &amp;lt;- textConnection(table)
        
        df &amp;lt;- read.csv(text_con, sep = &amp;quot;|&amp;quot;, header = F, stringsAsFactors = F)%&amp;gt;%
            dplyr::select_if(not_all_na)
        # Put in the appropriate column names and then add US senate as office 
        colnames(df)&amp;lt;- c(&amp;quot;precinct&amp;quot;, candidates)
        df &amp;lt;- df %&amp;gt;% 
            mutate(office = &amp;quot;US Senate&amp;quot;)%&amp;gt;%
            mutate(county = county_name)%&amp;gt;%
            select(county, precinct, office, everything())
        tables[[i]] &amp;lt;- df
    }
    if(length(tables)==1){
        out &amp;lt;- tables[[1]]
    }else{
       out &amp;lt;- dplyr::bind_rows(tables) 
    }
    out
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Supposing that we have stored all the 2018 Senate pdf urls in a vector called senate_urls, we can then make use of purrr::map and purrr::map_dfr() functions to run each through pdf_text and then our function, followed by tidyr::gather() to get our data into a long format.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# pdf_text() and map to the rescue

urls &amp;lt;- c(&amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-atlantic.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-bergen.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-burlington.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-camden.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-capemay.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-cumberland.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-essex.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-gloucester.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-hudson.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-hunterdon.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-mercer.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-middlesex.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-monmouth.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-morris.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-ocean.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-passaic.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-salem.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-somerset.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-sussex.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-union.pdf&amp;quot;,
                 &amp;quot;https://www.state.nj.us/state/elections/assets/pdf/election-results/2018/2018-general-election-results-us-senate-warren.pdf&amp;quot;)

senate_urls &amp;lt;- map(urls, pdf_text)

nj_senate &amp;lt;- senate_urls %&amp;gt;% 
    map_dfr(senate_clean_table)%&amp;gt;%
    gather(candidate, votes, -county, -precinct, -office)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now take at our now useful voting data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(nj_senate)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##            county         precinct    office candidate votes
## 1 Atlantic County     Absecon City US Senate  Menendez  1551
## 2 Atlantic County    Atlantic City US Senate  Menendez  6039
## 3 Atlantic County  Brigantine City US Senate  Menendez  1391
## 4 Atlantic County       Buena Boro US Senate  Menendez   583
## 5 Atlantic County Buena Vista Twp. US Senate  Menendez  1095
## 6 Atlantic County      Corbin City US Senate  Menendez    77
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
